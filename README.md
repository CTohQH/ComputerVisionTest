# Flower Classification with ResNet50

This project implements an end-to-end pipeline for fine-grained image classification using the **Oxford 102 Flowers** dataset. It leverages Transfer Learning with a pre-trained **ResNet50** backbone to achieve precision in classifying 102 different flower categories.

## ğŸš€ Key Features

*   **Hybrid Architecture**: Code is structured modularly in `src/` but **inlined** within notebooks. This ensures 100% portability, allowing notebooks to run standalone in **Google Colab** (without mounting Drive) or on a local machine.
*   **Advanced Preprocessing**: Implements a custom **Letterboxing** (padding) strategy to resize images to **640x640** while preserving aspect ratios, preventing distortion.
*   **Transfer Learning**: Uses a **ResNet50** model pre-trained on ImageNet. The backbone is frozen to extract robust features, training only the final classification head.
*   **Test-Time Augmentation (TTA)**: (Available in Evaluation) Boosts reliability by aggregating predictions from multiple augmented views of the same image.
*   **Interactive Demo**: Deployment-ready demonstration using **Gradio**, allowing real-time inference on custom images.

## ğŸ“‚ Project Structure

```
ComputerVisionTest/
â”œâ”€â”€ notebooks/                  # Standalone Jupyter Notebooks
â”‚   â”œâ”€â”€ 01_EDA.ipynb            # Data download & exploration
â”‚   â”œâ”€â”€ 02_Training_Combined.ipynb  # End-to-end Model Training
â”‚   â”œâ”€â”€ 03_Evaluation_Combined.ipynb # Comprehensive Evaluation
â”‚   â””â”€â”€ 04_Demo.ipynb           # Interactive Gradio App
â”œâ”€â”€ src/                        # Source Code (Reference Implementation)
â”‚   â”œâ”€â”€ data/                   # Dataset & Transforms
â”‚   â”œâ”€â”€ models/                 # ResNet definition
â”‚   â”œâ”€â”€ training/               # Loop & Callbacks
â”‚   â””â”€â”€ utils/                  # Evaluation metrics & Seeding
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # Documentation
```

## ğŸ› ï¸ Setup & Installation

### Option 1: Google Colab (Recommended)
1.  **Upload** the `.ipynb` files from the `notebooks/` directory to Colab.
2.  **Run** the cells. The notebooks are self-contained:
    *   They automatically detect the environment.
    *   They download the dataset directly to the Colab instance.
    *   They define all necessary model and training logic internally.
    *   **No separate setup or Drive mounting is required.**

### Option 2: Local Environment
1.  **Clone the repository**.
2.  **Install dependencies**:
    ```bash
    pip install -r requirements.txt
    ```
3.  **Run Jupyter**:
    ```bash
    jupyter lab
    ```

## ğŸš¦ Usage Guide

Execute the notebooks in the following sequence:

1.  **`01_EDA.ipynb`**: Downloads the Oxford 102 Flowers dataset and visualizes the class distribution and image samples.
2.  **`02_Training_Combined.ipynb`**: Trains the ResNet50 model.
    *   Initializes the model with ImageNet weights.
    *   Freezes the backbone.
    *   Trains the custom head for 102 classes.
    *   Saves the best weights to `best_model.pt`.
3.  **`03_Evaluation_Combined.ipynb`**: Loads `best_model.pt` and performs detailed analysis.
    *   Calculates Accuracy, F1-Score, and Confusion Matrix.
    *   Visualizes misclassified examples for error analysis.
4.  **`04_Demo.ipynb`**: Starts a local web server (Gradio) to upload and test images interactively.

## ğŸ“Š Technical Details

*   **Model**: ResNet50 (Frozen Backbone + Linear Head)
*   **Input Resolution**: 640x640 (Custom ResizeWithPad)
*   **Optimization**: Adam Optimizer with ReduceLROnPlateau scheduler.
*   **Regularization**: Early Stopping based on validation loss.
